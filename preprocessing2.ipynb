{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d6eb1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d96f01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50be6a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_events_recs_for_binary_metrics(events_train, events_test, recs, top_k=None):\n",
    "\n",
    "    \"\"\"\n",
    "    размечает пары <user_id, item_id> для общего множества пользователей признаками\n",
    "    - gt (ground truth)\n",
    "    - pr (prediction)\n",
    "    top_k: расчёт ведётся только для top k-рекомендаций\n",
    "    \"\"\"\n",
    "\n",
    "    events_test[\"gt\"] = True\n",
    "    common_users = set(events_test[\"user_id\"]) & set(recs[\"user_id\"])\n",
    "\n",
    "    print(f\"Common users: {len(common_users)}\")\n",
    "    \n",
    "    events_for_common_users = events_test[events_test[\"user_id\"].isin(common_users)].copy()\n",
    "    recs_for_common_users = recs[recs[\"user_id\"].isin(common_users)].copy()\n",
    "\n",
    "    recs_for_common_users = recs_for_common_users.sort_values([\"user_id\", \"score\"], ascending=[True, False])\n",
    "\n",
    "    # оставляет только те item_id, которые были в events_train, \n",
    "    # т. к. модель не имела никакой возможности давать рекомендации для новых айтемов\n",
    "    events_for_common_users = events_for_common_users[events_for_common_users[\"item_id\"].isin(events_train[\"item_id\"].unique())]\n",
    "\n",
    "    if top_k is not None:\n",
    "        recs_for_common_users = recs_for_common_users.groupby(\"user_id\").head(top_k)\n",
    "    \n",
    "    events_recs_common = events_for_common_users[[\"user_id\", \"item_id\", \"gt\"]].merge(\n",
    "        recs_for_common_users[[\"user_id\", \"item_id\", \"score\"]], \n",
    "        on=[\"user_id\", \"item_id\"], how=\"outer\")    \n",
    "\n",
    "    events_recs_common[\"gt\"] = events_recs_common[\"gt\"].fillna(False)\n",
    "    events_recs_common[\"pr\"] = ~events_recs_common[\"score\"].isnull()\n",
    "    \n",
    "    events_recs_common[\"tp\"] = events_recs_common[\"gt\"] & events_recs_common[\"pr\"]\n",
    "    events_recs_common[\"fp\"] = ~events_recs_common[\"gt\"] & events_recs_common[\"pr\"]\n",
    "    events_recs_common[\"fn\"] = events_recs_common[\"gt\"] & ~events_recs_common[\"pr\"]\n",
    "\n",
    "    return events_recs_common\n",
    "\n",
    "def compute_cls_metrics(events_recs_for_binary_metrics):\n",
    "    \n",
    "    groupper = events_recs_for_binary_metrics.groupby(\"user_id\")\n",
    "\n",
    "    # precision = tp / (tp + fp)\n",
    "    precision = groupper[\"tp\"].sum()/(groupper[\"tp\"].sum()+groupper[\"fp\"].sum())\n",
    "    precision = precision.fillna(0).mean()\n",
    "    \n",
    "    # recall = tp / (tp + fn)\n",
    "    recall = groupper[\"tp\"].sum()/(groupper[\"tp\"].sum() + groupper[\"fn\"].sum())\n",
    "    recall = recall.fillna(0).mean()\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9089cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_parquet(\"items.par\")\n",
    "events = pd.read_parquet(\"events.par\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89773e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "als_recommendations = pd.read_parquet(\"candidates/training/als_recommendations.parquet\")\n",
    "content_recommendations = pd.read_parquet(\"candidates/training/content_recommendations.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60b626be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428220 123223 120858\n"
     ]
    }
   ],
   "source": [
    "# зададим точку разбиения\n",
    "train_test_global_time_split_date = pd.to_datetime(\"2017-08-01\").date()\n",
    "\n",
    "train_test_global_time_split_idx = events[\"started_at\"] < train_test_global_time_split_date\n",
    "events_train = events[train_test_global_time_split_idx]\n",
    "events_test = events[~train_test_global_time_split_idx]\n",
    "\n",
    "# количество пользователей в train и test\n",
    "users_train = events_train[\"user_id\"].drop_duplicates()\n",
    "users_test = events_test[\"user_id\"].drop_duplicates()\n",
    "# количество пользователей, которые есть и в train, и в test\n",
    "common_users = set(users_train) & set(users_test)\n",
    "\n",
    "print(len(users_train), len(users_test), len(common_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc1eb8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "als_recommendations = (\n",
    "    als_recommendations\n",
    "    .merge(events_test[[\"user_id\", \"item_id\", \"rating\"]]\n",
    "               .rename(columns={\"rating\": \"rating_test\"}), \n",
    "           on=[\"user_id\", \"item_id\"], how=\"left\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70e5057a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3577/1296505728.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  events_train[\"user_id_enc\"] = user_encoder.transform(events_train[\"user_id\"])\n",
      "/tmp/ipykernel_3577/1296505728.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  events_test[\"user_id_enc\"] = user_encoder.transform(events_test[\"user_id\"])\n",
      "/tmp/ipykernel_3577/1296505728.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  events_train[\"item_id_enc\"] = item_encoder.transform(events_train[\"item_id\"])\n",
      "/tmp/ipykernel_3577/1296505728.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  events_test[\"item_id_enc\"] = item_encoder.transform(events_test[\"item_id\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id_enc max -  43304\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import sklearn.preprocessing\n",
    "\n",
    "items[\"genre_and_votes\"] = items[\"genre_and_votes\"].apply(eval)\n",
    "\n",
    "def get_item2genre_matrix(genres, items):\n",
    "\n",
    "    genre_names_to_id = genres.reset_index().set_index(\"name\")[\"genre_id\"].to_dict()\n",
    "    \n",
    "    # list to build CSR matrix\n",
    "    genres_csr_data = []\n",
    "    genres_csr_row_idx = []\n",
    "    genres_csr_col_idx = []\n",
    "    \n",
    "    for item_idx, (k, v) in enumerate(items.iterrows()):\n",
    "        if v[\"genre_and_votes\"] is None:\n",
    "            continue\n",
    "        for genre_name, votes in v[\"genre_and_votes\"].items():\n",
    "            genre_idx = genre_names_to_id[genre_name]\n",
    "            genres_csr_data.append(int(votes))\n",
    "            genres_csr_row_idx.append(item_idx)\n",
    "            genres_csr_col_idx.append(genre_idx)\n",
    "\n",
    "    genres_csr = scipy.sparse.csr_matrix((genres_csr_data, (genres_csr_row_idx, genres_csr_col_idx)), shape=(len(items), len(genres)))\n",
    "    # нормализуем, чтобы сумма оценок принадлежности к жанру была равна 1\n",
    "    genres_csr = sklearn.preprocessing.normalize(genres_csr, norm='l1', axis=1)\n",
    "    \n",
    "    return genres_csr \n",
    "\n",
    "# В genres_csr_col_idx добавляются индексы, соответствующие жанрам.\n",
    "\n",
    "# перекодируем идентификаторы пользователей: \n",
    "# из имеющихся в последовательность 0, 1, 2, ...\n",
    "user_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "user_encoder.fit(events[\"user_id\"])\n",
    "events_train[\"user_id_enc\"] = user_encoder.transform(events_train[\"user_id\"])\n",
    "events_test[\"user_id_enc\"] = user_encoder.transform(events_test[\"user_id\"])\n",
    "\n",
    "# перекодируем идентификаторы объектов: \n",
    "# из имеющихся в последовательность 0, 1, 2, ...\n",
    "item_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "item_encoder.fit(items[\"item_id\"])\n",
    "items[\"item_id_enc\"] = item_encoder.transform(items[\"item_id\"])\n",
    "events_train[\"item_id_enc\"] = item_encoder.transform(events_train[\"item_id\"])\n",
    "events_test[\"item_id_enc\"] = item_encoder.transform(events_test[\"item_id\"])\n",
    "\n",
    "print('item_id_enc max - ', events_train[\"item_id_enc\"].max())\n",
    "\n",
    "def get_genres(items):\n",
    "\n",
    "    \"\"\" \n",
    "    извлекает список жанров по всем книгам, \n",
    "    подсчитывает долю голосов по каждому их них\n",
    "    \"\"\"\n",
    "    \n",
    "    genres_counter = {}\n",
    "    \n",
    "    for k, v, in items.iterrows():\n",
    "        genre_and_votes = v[\"genre_and_votes\"]\n",
    "        if genre_and_votes is None or not isinstance(genre_and_votes, dict):\n",
    "            continue\n",
    "        for genre, votes in genre_and_votes.items():\n",
    "            # увеличиваем счётчик жанров\n",
    "            try:\n",
    "                genres_counter[genre] += votes\n",
    "            except KeyError:\n",
    "                genres_counter[genre] = 0\n",
    "\n",
    "    genres = pd.Series(genres_counter, name=\"votes\")\n",
    "    genres = genres.to_frame()\n",
    "    genres = genres.reset_index().rename(columns={\"index\": \"name\"})\n",
    "    genres.index.name = \"genre_id\"\n",
    "    \n",
    "    return genres\n",
    "   \n",
    "genres = get_genres(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39cef17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.sort_values(by=\"item_id_enc\")\n",
    "all_items_genres_csr = get_item2genre_matrix(genres, items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af258dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3577/210734134.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  events_train[\"read\"] = True\n"
     ]
    }
   ],
   "source": [
    "# разметим каждую рекомендацию признаком read\n",
    "events_train[\"read\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "056a6fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99849\n"
     ]
    }
   ],
   "source": [
    "# задаём точку разбиения\n",
    "split_date_for_labels = pd.to_datetime(\"2017-09-15\").date()\n",
    "\n",
    "split_date_for_labels_idx = events_test[\"started_at\"] < split_date_for_labels\n",
    "events_labels = events_test[split_date_for_labels_idx].copy()\n",
    "events_test_2 = events_test[~split_date_for_labels_idx].copy()\n",
    "\n",
    "# считаем количество уникальных пользователей в events_labels\n",
    "print(events_labels[\"user_id\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c421bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82993094"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загружаем рекомендации от двух базовых генераторов\n",
    "import pandas as pd \n",
    "\n",
    "als_recommendations = pd.read_parquet(\"candidates/training/als_recommendations.parquet\")\n",
    "content_recommendations = pd.read_parquet(\"candidates/training/content_recommendations.parquet\")\n",
    "\n",
    "candidates = pd.merge(\n",
    "    als_recommendations[[\"user_id\", \"item_id\", \"score\"]].rename(columns={\"score\": \"als_score\"}),\n",
    "    content_recommendations[[\"user_id\", \"item_id\", \"score\"]].rename(columns={\"score\": \"cnt_score\"}),\n",
    "    on=[\"user_id\", \"item_id\"],\n",
    "    how=\"outer\")\n",
    "\n",
    "len(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb0bc96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213708\n"
     ]
    }
   ],
   "source": [
    "# добавляем таргет к кандидатам со значением:\n",
    "# — 1 для тех item_id, которые пользователь прочитал\n",
    "# — 0, для всех остальных \n",
    "\n",
    "events_labels[\"target\"] = 1\n",
    "candidates = candidates.merge(events_labels[[\"user_id\", \"item_id\", \"target\"]], \n",
    "                                on=[\"user_id\", \"item_id\"],\n",
    "                                how=\"left\"\n",
    "                            )\n",
    "candidates[\"target\"] = candidates[\"target\"].fillna(0).astype(\"int\")\n",
    "\n",
    "# в кандидатах оставляем только тех пользователей, у которых есть хотя бы один положительный таргет\n",
    "candidates_to_sample = candidates.groupby(\"user_id\").filter(lambda x: x[\"target\"].sum() > 0)\n",
    "\n",
    "# для каждого пользователя оставляем только 4 негативных примера\n",
    "negatives_per_user = 4\n",
    "candidates_for_train = pd.concat([\n",
    "    # все позитивные примеры\n",
    "    candidates_to_sample.query(\"target == 1\"),\n",
    "    # по 4 отрицательных на пользователя\n",
    "    candidates_to_sample.query(\"target == 0\")\n",
    "        .groupby(\"user_id\")\n",
    "        .apply(lambda x: x.sample(negatives_per_user, random_state=0))\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "print(len(candidates_for_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "738da9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6526057\ttotal: 72.6ms\tremaining: 1m 12s\n",
      "100:\tlearn: 0.5118959\ttotal: 1.9s\tremaining: 16.9s\n",
      "200:\tlearn: 0.5111710\ttotal: 3.81s\tremaining: 15.1s\n",
      "300:\tlearn: 0.5105208\ttotal: 5.74s\tremaining: 13.3s\n",
      "400:\tlearn: 0.5100174\ttotal: 7.66s\tremaining: 11.4s\n",
      "500:\tlearn: 0.5095747\ttotal: 9.6s\tremaining: 9.56s\n",
      "600:\tlearn: 0.5091600\ttotal: 11.5s\tremaining: 7.66s\n",
      "700:\tlearn: 0.5087803\ttotal: 13.5s\tremaining: 5.74s\n",
      "800:\tlearn: 0.5084220\ttotal: 15.4s\tremaining: 3.81s\n",
      "900:\tlearn: 0.5080930\ttotal: 17.3s\tremaining: 1.9s\n",
      "999:\tlearn: 0.5078081\ttotal: 19.2s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f256ca958a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "# задаём имена колонок признаков и таргета\n",
    "features = ['als_score', 'cnt_score']\n",
    "target = 'target'\n",
    "\n",
    "# Create the Pool object\n",
    "train_data = Pool(\n",
    "    data=candidates_for_train[features], \n",
    "    label=candidates_for_train[target])\n",
    "\n",
    "# инициализируем модель CatBoostClassifier\n",
    "cb_model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='Logloss',\n",
    "    verbose=100,\n",
    "    random_seed=0\n",
    ")\n",
    "\n",
    "# тренируем модель\n",
    "cb_model.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17627c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14517152\n"
     ]
    }
   ],
   "source": [
    "# загружаем рекомендации от двух базовых генераторов\n",
    "als_recommendations_2 = pd.read_parquet(\"candidates/inference/als_recommendations.parquet\")\n",
    "content_recommendations_2 = pd.read_parquet(\"candidates/inference/content_recommendations.parquet\")\n",
    "\n",
    "candidates_to_rank = pd.merge(\n",
    "    als_recommendations_2[[\"user_id\", \"item_id\", \"score\"]].rename(columns={\"score\": \"als_score\"}),\n",
    "    content_recommendations_2[[\"user_id\", \"item_id\", \"score\"]].rename(columns={\"score\": \"cnt_score\"}),\n",
    "    on=[\"user_id\", \"item_id\"],\n",
    "    how=\"outer\"\n",
    ")\n",
    "\n",
    "# оставляем только тех пользователей, что есть в тестовой выборке, для экономии ресурсов\n",
    "candidates_to_rank = candidates_to_rank[candidates_to_rank[\"user_id\"].isin(events_test_2[\"user_id\"].drop_duplicates())]\n",
    "print(len(candidates_to_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f143dcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7519400"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_data = Pool(data=candidates_to_rank[features])\n",
    "predictions = cb_model.predict_proba(inference_data)\n",
    "\n",
    "candidates_to_rank[\"cb_score\"] = predictions[:, 1]\n",
    "\n",
    "# для каждого пользователя проставляем rank, начиная с 1 — это максимальный cb_score\n",
    "candidates_to_rank = candidates_to_rank.sort_values([\"user_id\", \"cb_score\"], ascending=[True, False])\n",
    "candidates_to_rank[\"rank\"] = candidates_to_rank.groupby(\"user_id\").cumcount() + 1\n",
    "\n",
    "max_recommendations_per_user = 100\n",
    "final_recommendations = candidates_to_rank.query(\"rank <= @max_recommendations_per_user\")\n",
    "\n",
    "len(final_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c33df369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_recommendations.to_parquet(\"final_recommendations_feat.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "949cd651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items[\"age\"] = 2018 - items[\"publication_year\"]\n",
    "invalid_age_idx = items[\"age\"] < 0\n",
    "items.loc[invalid_age_idx, \"age\"] = np.nan\n",
    "items[\"age\"] = items[\"age\"].astype(\"float\")\n",
    "\n",
    "candidates_for_train = candidates_for_train.merge(\n",
    "    items[[\"item_id\", \"age\", \"average_rating\"]],\n",
    "    on=[\"item_id\"],\n",
    "    how=\"outer\"\n",
    ")\n",
    "candidates_to_rank = candidates_to_rank.merge(\n",
    "    items[[\"item_id\", \"age\", \"average_rating\"]],\n",
    "    on=[\"item_id\"],\n",
    "    how=\"outer\"\n",
    ")\n",
    "candidates_to_rank[\"age\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "001195fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_user_features(events):\n",
    "    \"\"\" считает пользовательские признаки \"\"\"\n",
    "    \n",
    "    user_features = events.groupby(\"user_id\").agg(\n",
    "        reading_years=(\"started_at\", lambda x: (x.max() - x.min()).days / 365.25),\n",
    "        books_read=(\"item_id\", \"nunique\"),\n",
    "        rating_avg=(\"rating\", \"mean\"),\n",
    "        rating_std=(\"rating\", \"std\")\n",
    "    )\n",
    "    \n",
    "    user_features[\"books_per_year\"] = user_features[\"books_read\"] / user_features[\"reading_years\"]\n",
    "    \n",
    "    return user_features\n",
    "    \n",
    "user_features_for_train = get_user_features(events_train)\n",
    "candidates_for_train = candidates_for_train.merge(user_features_for_train, on=\"user_id\", how=\"left\")\n",
    "  \n",
    "# оставим только тех пользователей, что есть в тесте, для экономии ресурсов\n",
    "events_inference = pd.concat([events_train, events_labels])\n",
    "events_inference = events_inference[events_inference[\"user_id\"].isin(events_test[\"user_id\"].drop_duplicates())]\n",
    "\n",
    "user_features_for_ranking = get_user_features(events_inference)\n",
    "\n",
    "candidates_to_rank = candidates_to_rank.merge(\n",
    "    user_features_for_ranking, on=\"user_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "candidates_for_train[\"books_read\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d5edf24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038488976462249"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# определяем индексы топ-10 жанров и всех остальных\n",
    "genres_top_k = 10\n",
    "genres_top_idx = genres.sort_values(\"votes\", ascending=False).head(genres_top_k).index\n",
    "genres_others_idx = list(set(genres.index) - set(genres_top_idx))\n",
    "\n",
    "genres_top_columns = [f\"genre_{id}\" for id in genres_top_idx]\n",
    "genres_others_column = \"genre_others\"\n",
    "genre_columns = genres_top_columns + [genres_others_column]\n",
    "\n",
    "# составляем таблицу принадлежности книг к жанрам\n",
    "item_genres = (\n",
    "    pd.concat([\n",
    "        # топ жанров\n",
    "        pd.DataFrame(all_items_genres_csr[:, genres_top_idx].toarray(), columns=genres_top_columns),\n",
    "        # все остальные жанры\n",
    "        pd.DataFrame(all_items_genres_csr[:, genres_others_idx].sum(axis=1), columns=[genres_others_column])\n",
    "        ],\n",
    "        axis=1)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"item_id_enc\"})\n",
    ")\n",
    "# убрать всё, что мы уже когда-то навешивали\n",
    "genre_cols_existing = [c for c in items.columns if c.startswith(\"genre_\")]\n",
    "if genre_cols_existing:\n",
    "    items = items.drop(columns=genre_cols_existing)\n",
    "# объединяем информацию принадлежности книг к жанрам с основной информацией о книгах\n",
    "items = items.merge(item_genres, on=\"item_id_enc\", how=\"left\")\n",
    "\n",
    "def get_user_genres(events, items, item_genre_columns):\n",
    "    user_genres = (\n",
    "        events\n",
    "        .merge(items[[\"item_id\"] + item_genre_columns], on=\"item_id\", how=\"left\")\n",
    "        .groupby(\"user_id\")[item_genre_columns].mean()\n",
    "    )\n",
    "    return user_genres\n",
    "    \n",
    "user_genres_for_train = get_user_genres(events_train, items, genre_columns)\n",
    "candidates_for_train = candidates_for_train.merge(user_genres_for_train, on=\"user_id\", how=\"left\")\n",
    "\n",
    "user_genres_for_ranking = get_user_genres(events_inference, items, genre_columns)\n",
    "candidates_to_rank = candidates_to_rank.merge(user_genres_for_ranking, on=\"user_id\", how=\"left\")\n",
    "\n",
    "romance_id = genres.query(\"name == 'Romance'\").index[0]\n",
    "romance_col = f\"genre_{romance_id}\"\n",
    "candidates_for_train[romance_col].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bacaf12",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56a746bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6467298\ttotal: 27.9ms\tremaining: 27.9s\n",
      "100:\tlearn: 0.4657506\ttotal: 2.63s\tremaining: 23.4s\n",
      "200:\tlearn: 0.4575146\ttotal: 5.22s\tremaining: 20.7s\n",
      "300:\tlearn: 0.4515641\ttotal: 7.83s\tremaining: 18.2s\n",
      "400:\tlearn: 0.4467942\ttotal: 10.5s\tremaining: 15.6s\n",
      "500:\tlearn: 0.4423475\ttotal: 13.1s\tremaining: 13s\n",
      "600:\tlearn: 0.4383226\ttotal: 15.7s\tremaining: 10.4s\n",
      "700:\tlearn: 0.4347273\ttotal: 18.3s\tremaining: 7.79s\n",
      "800:\tlearn: 0.4312752\ttotal: 20.9s\tremaining: 5.19s\n",
      "900:\tlearn: 0.4279893\ttotal: 23.7s\tremaining: 2.61s\n",
      "999:\tlearn: 0.4249013\ttotal: 26.3s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f263866bcd0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "candidates_for_train = candidates_for_train[~candidates_for_train[\"target\"].isna()].copy()\n",
    "candidates_for_train[\"target\"] = candidates_for_train[\"target\"].astype(int)\n",
    "\n",
    "# задаём имена колонок признаков и таргета\n",
    "features = ['als_score', 'cnt_score', \n",
    "    'age', 'average_rating', 'reading_years', 'books_read', \n",
    "    'rating_avg', 'rating_std', \n",
    "    'books_per_year'] + genre_columns\n",
    "target = 'target'\n",
    "\n",
    "# создаём Pool\n",
    "train_data = Pool(\n",
    "    data=candidates_for_train[features], \n",
    "    label=candidates_for_train[target])\n",
    "\n",
    "# инициализируем модель CatBoostClassifier\n",
    "cb_model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='Logloss',\n",
    "    verbose=100,\n",
    "    random_seed=0,\n",
    ")\n",
    "\n",
    "# тренируем модель\n",
    "cb_model.fit(train_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9db1ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_data = Pool(data=candidates_to_rank[features])\n",
    "predictions = cb_model.predict_proba(inference_data)\n",
    "\n",
    "candidates_to_rank[\"cb_score\"] = predictions[:, 1]\n",
    "\n",
    "# для каждого пользователя проставим rank, начиная с 1 — это максимальный cb_score\n",
    "candidates_to_rank = candidates_to_rank.sort_values([\"user_id\", \"cb_score\"], ascending=[True, False])\n",
    "candidates_to_rank[\"rank\"] = candidates_to_rank.groupby(\"user_id\").cumcount() + 1\n",
    "\n",
    "max_recommendations_per_user = 100\n",
    "final_recommendations = candidates_to_rank.query(\"rank <= @max_recommendations_per_user\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e61d6f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_recommendations.to_parquet(\"final_recommendations_feat.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af00fb92",
   "metadata": {},
   "source": [
    "#### **Задание 5 из 6**\n",
    "\n",
    "Используя отложенную тестовую выборку `events_test_2`, посчитаем метрики `recall` и `precision` для полученных рекомендаций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "832c099d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common users: 75194\n",
      "precision: 0.011, recall: 0.029\n"
     ]
    }
   ],
   "source": [
    "# для экономии ресурсов оставим события только тех пользователей, \n",
    "# для которых следует оценить рекомендации\n",
    "events_inference = pd.concat([events_train, events_labels])\n",
    "events_inference = events_inference[events_inference[\"user_id\"].isin(events_test_2[\"user_id\"].drop_duplicates())]\n",
    "\n",
    "cb_events_recs_for_binary_metrics_5 = process_events_recs_for_binary_metrics(\n",
    "    events_inference,\n",
    "    events_test_2,  # <- тестовая выборка для валидации\n",
    "    final_recommendations.rename(columns={\"cb_score\": \"score\"}), \n",
    "    top_k=5         # <- считаем precision@5 и recall@5\n",
    ")\n",
    "\n",
    "cb_precision_5, cb_recall_5 = compute_cls_metrics(cb_events_recs_for_binary_metrics_5)\n",
    "\n",
    "print(f\"precision: {cb_precision_5:.3f}, recall: {cb_recall_5:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50184949",
   "metadata": {},
   "source": [
    "### Проверка важности признаков\n",
    "\n",
    "Любопытно понять, какие признаки вносят наибольший вклад в ранжирование. Алгоритм CatBoost позволяет получить такую информацию (англ. feature importance), которая генерируется во время тренировки модели. Для этого используйте метод `get_feature_importance()`.\n",
    "\n",
    "#### **Задание 6**\n",
    "\n",
    "Выполним код для получения информации о важности признаков. Выведем список признаков `feature_importance` в порядке убывания их важности.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1572d132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       fi\n",
      "als_score       28.750790\n",
      "age             18.341400\n",
      "average_rating  14.320395\n",
      "books_read       6.095059\n",
      "reading_years    3.497930\n",
      "cnt_score        3.134267\n",
      "genre_18         2.627597\n",
      "genre_others     2.580376\n",
      "genre_1          2.570093\n",
      "genre_25         2.368419\n",
      "books_per_year   2.285353\n",
      "genre_34         2.174140\n",
      "genre_16         1.576704\n",
      "genre_38         1.569290\n",
      "genre_33         1.516361\n",
      "genre_24         1.513510\n",
      "rating_avg       1.486050\n",
      "genre_20         1.414986\n",
      "genre_5          1.162734\n",
      "rating_std       1.014546\n"
     ]
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame(\n",
    "    cb_model.get_feature_importance(),\n",
    "    index=features,\n",
    "    columns=[\"fi\"]\n",
    ")\n",
    "\n",
    "feature_importance = feature_importance.sort_values(\"fi\", ascending=False)\n",
    "print(feature_importance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
